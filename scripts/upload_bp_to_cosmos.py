#!/usr/bin/env python3
"""
Upload BP 10-K Embeddings to Cosmos DB for RAG queries
"""

import os
import sys
import json
from motor.motor_asyncio import AsyncIOMotorClient
import asyncio
from dotenv import load_dotenv

# Add backend to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

load_dotenv()

MONGO_URL = os.getenv("COSMOS_MONGODB_URI", "mongodb://localhost:27017")
DB_NAME = "sre_hackathon"
COLLECTION_NAME = "bp_documents"

async def upload_embeddings():
    """Upload BP embeddings to Cosmos DB"""

    print("\n" + "="*70)
    print("  BP 10-K Embeddings ‚Üí Cosmos DB Upload")
    print("="*70 + "\n")

    # Load embeddings
    embeddings_files = [
        "demo-data/bp_2023_embeddings.json",
        "demo-data/bp_2024_embeddings.json"
    ]

    all_documents = []
    for file_path in embeddings_files:
        full_path = os.path.join(os.path.dirname(__file__), '..', file_path)
        print(f"üìñ Loading {os.path.basename(file_path)}...")

        with open(full_path, 'r') as f:
            docs = json.load(f)
            all_documents.extend(docs)
            print(f"   ‚úÖ Loaded {len(docs)} documents\n")

    print(f"üìä Total documents to upload: {len(all_documents)}\n")

    # Connect to MongoDB
    print(f"üîå Connecting to MongoDB: {MONGO_URL}")
    client = AsyncIOMotorClient(MONGO_URL)
    db = client[DB_NAME]
    collection = db[COLLECTION_NAME]

    # Drop existing collection to start fresh
    print(f"üóëÔ∏è  Dropping existing collection: {COLLECTION_NAME}")
    await collection.drop()
    print("   ‚úÖ Collection dropped\n")

    # Upload documents in batches (reduced due to Cosmos DB RU limits)
    batch_size = 10  # Smaller batches for Cosmos DB
    total_uploaded = 0
    import time

    print(f"üì§ Uploading documents in batches of {batch_size}...")
    for i in range(0, len(all_documents), batch_size):
        batch = all_documents[i:i + batch_size]

        # Prepare documents for MongoDB
        mongo_docs = []
        for doc in batch:
            mongo_doc = {
                "document_id": doc["document_id"],
                "year": doc["year"],
                "source": doc["source"],
                "text": doc["text"],
                "embedding": doc["embedding"],
                "word_count": doc["word_count"],
                "metadata": doc["metadata"]
            }
            mongo_docs.append(mongo_doc)

        # Insert batch with retry
        max_retries = 3
        for attempt in range(max_retries):
            try:
                result = await collection.insert_many(mongo_docs)
                total_uploaded += len(result.inserted_ids)
                print(f"   Batch {i//batch_size + 1}: Uploaded {len(result.inserted_ids)} documents " +
                      f"(Total: {total_uploaded}/{len(all_documents)})")
                break
            except Exception as e:
                if "429" in str(e) or "TooManyRequests" in str(e):
                    if attempt < max_retries - 1:
                        wait_time = 5 * (attempt + 1)
                        print(f"   ‚è∏Ô∏è  Rate limited, waiting {wait_time}s...")
                        time.sleep(wait_time)
                    else:
                        print(f"   ‚ùå Failed after {max_retries} retries")
                        raise
                else:
                    raise

        # Add delay between batches to avoid throttling
        time.sleep(1)

    print(f"\n‚úÖ Upload complete!\n")

    # Create index on document_id for faster lookups
    print("üìá Creating index on document_id...")
    await collection.create_index("document_id", unique=True)
    print("   ‚úÖ Index created\n")

    # Verify upload
    count = await collection.count_documents({})
    print(f"üìä Verification:")
    print(f"   ‚Ä¢ Documents in collection: {count}")
    print(f"   ‚Ä¢ Expected: {len(all_documents)}")
    print(f"   ‚Ä¢ Match: {'‚úÖ YES' if count == len(all_documents) else '‚ùå NO'}\n")

    # Sample query
    print("üîç Sample query test:")
    sample = await collection.find_one({"year": "2024"})
    if sample:
        print(f"   ‚úÖ Found document: {sample['document_id']}")
        print(f"      Year: {sample['year']}")
        print(f"      Source: {sample['source']}")
        print(f"      Text preview: {sample['text'][:100]}...")
        print(f"      Embedding dimensions: {len(sample['embedding'])}")
    else:
        print("   ‚ùå No documents found")

    print("\n" + "="*70)
    print("‚úÖ BP Embeddings Successfully Uploaded to Cosmos DB!")
    print("="*70 + "\n")

    print("üí° Next Steps:")
    print("   1. Test RAG safety analysis endpoint")
    print("   2. Query: 'What are BP's hard hat requirements?'")
    print("   3. Use /sre/images/safety-analysis with BP RAG\n")

    client.close()

if __name__ == "__main__":
    asyncio.run(upload_embeddings())
